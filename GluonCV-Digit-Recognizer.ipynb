{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition using Convolutional Neural Network\n",
    "In this project, we will write a full end-to-end training process using gluon and MXNet.We will train the LeNet-5 classifier network on the MNIST dataset. The steps that we will follow are to prepare the dataset, train the network, and evaluate it's performance on the held out dataset. So lets get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lets load all the essential Libraries\n",
    "We will be working with GluonCV for image recognition. It is a part of Apache MXNet ecosystem, a flexible and efficient library for deep learning. \n",
    "* *GluonCV* provides implementations of state-of-the-art deep learning algorithms in computer vision. It aims to help engineers, researchers, and students quickly prototype products, validate new ideas and learn computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all Libraries and essential Functions\n",
    "from mxnet import gluon, metric, autograd, init, nd\n",
    "from mxnet.gluon.data.vision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "Once we have imported the functionalites, its time to get the data. MXNet has the MNIST data in *`gluon.data.vision.datasets`*. The function defined below returns training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Datasets\n",
    "def get_mnist_data():\n",
    "    train_data = gluon.data.vision.datasets.MNIST(train=True)\n",
    "    #train_data._label[train_data._label > 0] = 1\n",
    "\n",
    "    val_data = gluon.data.vision.datasets.MNIST(train=False)\n",
    "    #val_data._label[val_data._label > 0] = 1\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look\n",
    "Now that the dataset is loaded, lets take a look at the sample from training set. We can visualize a sample image with its label using Matplotlib. To view a different sample, just change the index number at the bottom of the below defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'numpy.uint8'>\n",
      "Label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See samples from the dataset\n",
    "from matplotlib.pylab import imshow\n",
    "\n",
    "def view_sample(sample_idx):\n",
    "    sample = train_data[sample_idx]\n",
    "    data = sample[0]\n",
    "    label = sample[1]\n",
    "    \n",
    "    imshow(data[:,:,0].asnumpy(), cmap='gray')\n",
    "    print(\"Data type: {}\".format(data.dtype))\n",
    "    print(\"Label: {}\".format(label))\n",
    "\n",
    "#Enter the sample number to view from training dataset    \n",
    "view_sample(350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'numpy.uint8'>\n",
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sample(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "Data preprocessing and transformation is a common step performed in machine learning to make training robust. Here we perform two types of transformation.\n",
    "* `ToTensor()`: Converts an image NDArray of shape (H x W x C) in the range [0, 255] to a float32 tensor NDArray of shape (C x H x W) in the range [0, 1].\n",
    "\n",
    "* `Normalize()`: Normalize an tensor of shape (C x H x W) or (N x C x H x W) with mean and standard deviation.\n",
    "\n",
    "We have defined the tranformation function below. We will use this function in data loading step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a transformation function\n",
    "transform_fn = transforms.Compose([transforms.ToTensor(),transforms.Normalize(0.13,0.31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders\n",
    "The dataloader is essentially an iterator which goes through our entire dataset, minibatch by minibatch until all of the dataset samples have been used during training, signaling the end of one epoch. To train neural networks, we typically repeat multiple epochs until convergence of the network parameters.\n",
    "We define two dataloaders below, one for training data and one for validation data.\n",
    "\n",
    "The transformations are applied while fetching the data batch. The transformation function that we defined above will be used while loading the dataset to perform transformation. This is called *`LAZY TRANSFORMATION`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_data,val_data,transform_fn,batch):\n",
    "    \n",
    "    train_dataloader = gluon.data.DataLoader(train_data.transform_first(transform_fn),\n",
    "                                      batch_size = batch,\n",
    "                                       shuffle=True)\n",
    "    \n",
    "    validation_dataloader = gluon.data.DataLoader(val_data.transform_first(transform_fn),\n",
    "                                     batch_size = batch,\n",
    "                                     shuffle=False)\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_data_loaders(train_data, val_data, transform_fn, batch = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Network\n",
    "For multiclass classification, we will use LeNet-5 architecture to define our network. \n",
    "* `LeNet-5 CNN` architecture is made up of 7 layers. The layer composition consists of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.\n",
    "To learn more about this architecture, please refer to the article below.\n",
    "\n",
    "https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "net.add(gluon.nn.Conv2D(channels=6, kernel_size=5, activation='relu'), #C1\n",
    "        gluon.nn.MaxPool2D(pool_size=2, strides=2),                    #S2\n",
    "        gluon.nn.Conv2D(channels=16, kernel_size=3, activation='relu'),#C3\n",
    "        gluon.nn.MaxPool2D(pool_size=2, strides=2),                    #S4\n",
    "        gluon.nn.Flatten(),                                            #Flatten\n",
    "        gluon.nn.Dense(120, activation=\"relu\"),                        #C5\n",
    "        gluon.nn.Dense(84, activation=\"relu\"),                         #F6\n",
    "        gluon.nn.Dense(10))                                            #Output Layer\n",
    "net.initialize(init=init.Xavier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "In this step, we will train our network on training data. We follow the steps to write the loop as follows.\n",
    "* Create the loss function. This should be a loss function suitable for multi-class classification.\n",
    "* Create the metric accumulator. This should the compute and store the accuracy of the model during training\n",
    "* Create the trainer with the `adam` optimizer and learning rate of `0.002`\n",
    "\n",
    "\n",
    "The function returns the trained network after n epochs and training accurracy of each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, training_dataloader, batch_size, epochs):\n",
    "    \"\"\"\n",
    "    Should take an initialized network and train that network using data from the data loader.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param training_dataloader: the training DataLoader provides batches for data for every iteration\n",
    "    :type training_dataloader: gluon.data.DataLoader\n",
    "    \n",
    "    :param batch_size: batch size for the DataLoader.\n",
    "    :type batch_size: int\n",
    "    \n",
    "    :param epochs: number of epochs to train the DataLoader\n",
    "    :type epochs: int\n",
    "    \n",
    "    :return: tuple of trained network and the final training accuracy\n",
    "    :rtype: (gluon.Block, float)\n",
    "    \"\"\"\n",
    "    \n",
    "    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    train_acc = metric.Accuracy()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate' : 0.002})\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        \n",
    "        for data,label in training_dataloader:\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = loss_fn(output,label)\n",
    "                \n",
    "            loss.backward()\n",
    "            \n",
    "            trainer.step(batch_size)\n",
    "            train_loss += loss.mean().asscalar()\n",
    "            \n",
    "            train_acc.update(label,output)\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        print(\"Training Accuracy {}\".format(train_acc.get()[1]))\n",
    "        \n",
    "    training_accuracy = train_acc.get()[1]\n",
    "\n",
    "    return network, training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training Accuracy 0.9431333333333334\n",
      "Epoch 1\n",
      "Training Accuracy 0.9625166666666667\n",
      "Epoch 2\n",
      "Training Accuracy 0.9705944444444444\n",
      "Epoch 3\n",
      "Training Accuracy 0.975275\n",
      "Epoch 4\n",
      "Training Accuracy 0.97854\n"
     ]
    }
   ],
   "source": [
    "network, train_acc = train(net, train_loader, 128, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the network and tested its accuracy on the training set, which is pretty decent, we will also go ahead and test it for validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Loop\n",
    "We will take the set of same steps that we did in the training loop. For the validation loop, we only need to predict the label of the data and compute the accuracy. We have defined a validation loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, validation_dataloader):\n",
    "    \"\"\"\n",
    "    Should compute the accuracy of the network on the validation set.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param validation_dataloader: the training DataLoader provides batches for data for every iteration\n",
    "    :type validation_dataloader: gluon.data.DataLoader\n",
    "    \n",
    "    :return: validation accuracy\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_acc = metric.Accuracy()\n",
    "    for data, label in validation_dataloader:\n",
    "        output = net(data)\n",
    "        valid_acc.update(label,output)\n",
    "        \n",
    "    validation_accuracy = valid_acc.get()[1]\n",
    "\n",
    "    return validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is 0.9889\n"
     ]
    }
   ],
   "source": [
    "val_acc = validate(net,val_loader)\n",
    "print(\"The validation accuracy is {}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally\n",
    "To conclude, we used a LeNet-5 CNN for image classification of MNIST data. We are able to predict the labels of hand-written digits using this network. We performed data loading, data transformation, network definition and training and calculated training and validation accuracy.\n",
    "\n",
    "This project is based on the course that I completed on Coursera. `AWS Computer Vision: Getting Started with GluonCV`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
